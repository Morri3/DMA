{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e20e5b-5ca7-402c-a5c9-e5ff1edcf528",
   "metadata": {},
   "source": [
    "# **Acoustic Extinguisher Fire Dataset**\n",
    "\n",
    "#### **TODO：后面记得修改注释、md文字的格式、大小等！**\n",
    "This is the Coursework 2 for ***COMP4131 Data Modelling and Analysis***. The code follows Google Cloud's Data Science Road Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e83c7f-df8b-480a-be81-9067de027a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used in this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097d0b8-4c26-4e7c-bac9-3d1d8d63dd80",
   "metadata": {},
   "source": [
    "## Stage 1 · Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55913014-094a-41f0-bb89-cb3051376d93",
   "metadata": {},
   "source": [
    "### Step 1 · Data Ingestion\n",
    "【Step Description】\n",
    "- The data is collected from [Acoustic-Extinguisher-Fire-Dataset - Kaggle](https://www.kaggle.com/datasets/muratkokludataset/acoustic-extinguisher-fire-dataset/data).\n",
    "- I have downloaded the dataset from **Kaggle**, so the first step is reading it from an XLSX file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3e912e-0d3c-419d-81ca-541f03d80fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>2.6</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>3.2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>4.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17439</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17440</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17442 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE      FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "0         1  gasoline        10       96      0.0         75       0\n",
       "1         1  gasoline        10       96      0.0         72       1\n",
       "2         1  gasoline        10       96      2.6         70       1\n",
       "3         1  gasoline        10       96      3.2         68       1\n",
       "4         1  gasoline        10      109      4.5         67       1\n",
       "...     ...       ...       ...      ...      ...        ...     ...\n",
       "17437     7       lpg       190       86      2.2          5       0\n",
       "17438     7       lpg       190       84      2.0          4       0\n",
       "17439     7       lpg       190       80      1.5          3       0\n",
       "17440     7       lpg       190       76      0.4          2       0\n",
       "17441     7       lpg       190       72      0.0          1       0\n",
       "\n",
       "[17442 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from an XLSX file\n",
    "df_raw = pd.read_excel(\"Acoustic_Extinguisher_Fire_Dataset.xlsx\", \"A_E_Fire_Dataset\", index_col=None, na_values=[\"NA\"])\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d2182-3950-4661-b81b-b6c755d2e835",
   "metadata": {},
   "source": [
    "### Step 2 · Data Preparation\n",
    "【Step Description】\n",
    "- Cleaning, deduplication, and integration of datasets. Handling missing values and ensuring data consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5acf7-e881-4f88-8b47-c3d6606a72df",
   "metadata": {},
   "source": [
    "##### **Task** 【Statistic summary and information】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e1f0e9-2242-481b-a4e8-862f8f5ac935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.411765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.379142</td>\n",
       "      <td>6.975634</td>\n",
       "      <td>31.611111</td>\n",
       "      <td>0.497821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.750977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.773826</td>\n",
       "      <td>8.164096</td>\n",
       "      <td>4.736169</td>\n",
       "      <td>20.939149</td>\n",
       "      <td>0.500010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SIZE      FUEL      DISTANCE       DESIBEL       AIRFLOW  \\\n",
       "count   17442.000000     17442  17442.000000  17442.000000  17442.000000   \n",
       "unique           NaN         4           NaN           NaN           NaN   \n",
       "top              NaN  gasoline           NaN           NaN           NaN   \n",
       "freq             NaN      5130           NaN           NaN           NaN   \n",
       "mean        3.411765       NaN    100.000000     96.379142      6.975634   \n",
       "std         1.750977       NaN     54.773826      8.164096      4.736169   \n",
       "min         1.000000       NaN     10.000000     72.000000      0.000000   \n",
       "25%         2.000000       NaN     50.000000     90.000000      3.200000   \n",
       "50%         3.000000       NaN    100.000000     95.000000      5.800000   \n",
       "75%         5.000000       NaN    150.000000    104.000000     11.200000   \n",
       "max         7.000000       NaN    190.000000    113.000000     17.000000   \n",
       "\n",
       "           FREQUENCY        STATUS  \n",
       "count   17442.000000  17442.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean       31.611111      0.497821  \n",
       "std        20.939149      0.500010  \n",
       "min         1.000000      0.000000  \n",
       "25%        14.000000      0.000000  \n",
       "50%        27.500000      0.000000  \n",
       "75%        47.000000      1.000000  \n",
       "max        75.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a quick statistic summary of dataframe\n",
    "df_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b0d108-3bdb-4b40-88c1-9ce92e81e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17442 entries, 0 to 17441\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SIZE       17442 non-null  int64  \n",
      " 1   FUEL       17442 non-null  object \n",
      " 2   DISTANCE   17442 non-null  int64  \n",
      " 3   DESIBEL    17442 non-null  int64  \n",
      " 4   AIRFLOW    17442 non-null  float64\n",
      " 5   FREQUENCY  17442 non-null  int64  \n",
      " 6   STATUS     17442 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 954.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check info of dataframe\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391a6420-cd9a-4abd-b9b5-dcbcaba7e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>2.6</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>3.2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>4.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>7.8</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>103</td>\n",
       "      <td>9.7</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>12.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>13.3</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SIZE      FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "0     1  gasoline        10       96      0.0         75       0\n",
       "1     1  gasoline        10       96      0.0         72       1\n",
       "2     1  gasoline        10       96      2.6         70       1\n",
       "3     1  gasoline        10       96      3.2         68       1\n",
       "4     1  gasoline        10      109      4.5         67       1\n",
       "5     1  gasoline        10      109      7.8         66       1\n",
       "6     1  gasoline        10      103      9.7         65       1\n",
       "7     1  gasoline        10       95     12.0         60       1\n",
       "8     1  gasoline        10      102     13.3         55       1\n",
       "9     1  gasoline        10       93     15.4         52       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first ten rows\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de675d6-73a1-4559-a3a7-dcd438509cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>91</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17434</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>91</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17435</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>91</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>87</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17439</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17440</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "17432     7  lpg       190       91      1.6         10       0\n",
       "17433     7  lpg       190       92      2.0          9       0\n",
       "17434     7  lpg       190       91      1.9          8       0\n",
       "17435     7  lpg       190       91      1.6          7       0\n",
       "17436     7  lpg       190       87      2.5          6       0\n",
       "17437     7  lpg       190       86      2.2          5       0\n",
       "17438     7  lpg       190       84      2.0          4       0\n",
       "17439     7  lpg       190       80      1.5          3       0\n",
       "17440     7  lpg       190       76      0.4          2       0\n",
       "17441     7  lpg       190       72      0.0          1       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the last five rows\n",
    "df_raw.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6721f10-ebad-465d-9dc1-ec69c3327e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIZE           int64\n",
       "FUEL          object\n",
       "DISTANCE       int64\n",
       "DESIBEL        int64\n",
       "AIRFLOW      float64\n",
       "FREQUENCY      int64\n",
       "STATUS         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types of each column \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c58251-9ba3-417e-85c3-70deff2d2b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'SIZE' having values:\n",
      "[1 2 3 4 5 6 7]\n",
      "\n",
      "Column 'FUEL' having values:\n",
      "['gasoline' 'kerosene' 'lpg' 'thinner']\n",
      "\n",
      "Column 'DISTANCE' having values:\n",
      "[ 10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180\n",
      " 190]\n",
      "\n",
      "Column 'DESIBEL' having values:\n",
      "[ 72  74  75  76  78  79  80  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113]\n",
      "\n",
      "Column 'AIRFLOW' having values:\n",
      "[ 0.   0.4  0.8  1.   1.1  1.3  1.4  1.5  1.6  1.7  1.9  2.   2.1  2.2\n",
      "  2.3  2.5  2.6  2.7  2.8  2.9  3.   3.1  3.2  3.3  3.4  3.6  3.7  3.8\n",
      "  3.9  4.   4.2  4.3  4.4  4.5  4.6  4.8  4.9  5.   5.2  5.3  5.4  5.6\n",
      "  5.7  5.8  6.   6.1  6.3  6.4  6.5  6.7  6.8  7.   7.1  7.2  7.3  7.4\n",
      "  7.5  7.7  7.8  7.9  8.1  8.2  8.3  8.5  8.6  8.7  8.8  8.9  9.   9.1\n",
      "  9.2  9.3  9.5  9.6  9.7  9.9 10.  10.2 10.3 10.4 10.5 10.6 10.7 10.9\n",
      " 11.  11.2 11.3 11.5 11.6 11.8 11.9 12.  12.2 12.3 12.5 12.6 12.8 12.9\n",
      " 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.8 13.9 14.  14.1 14.2 14.3 14.4\n",
      " 14.5 14.6 14.8 14.9 15.  15.1 15.2 15.4 15.5 15.7 16.  16.1 16.3 16.6\n",
      " 17. ]\n",
      "\n",
      "Column 'FREQUENCY' having values:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 30 32 33 34 35 36 38 40 42 44 45 46 47 48 50 51 52 55 60 65\n",
      " 66 67 68 70 72 75]\n",
      "\n",
      "Column 'STATUS' having values:\n",
      "[0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all unique values of features and label\n",
    "columns = [\"SIZE\", \"FUEL\", \"DISTANCE\", \"DESIBEL\", \"AIRFLOW\", \"FREQUENCY\", \"STATUS\"]\n",
    "for column in columns:\n",
    "    print(f\"Column '{column}' having values:\\n{np.sort(df_raw[column].unique())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dec6418-b6df-4f53-8791-52feb8354636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SIZE, FUEL, DISTANCE, DESIBEL, AIRFLOW, FREQUENCY, STATUS]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output all rows having NaN\n",
    "df_raw[df_raw.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804f306-e13d-462c-87eb-29e09b5869fb",
   "metadata": {},
   "source": [
    "**Analysis according to the above statistic summary and information**:\n",
    "1. The result shows that there are 17442 rows (data) and 7 columns (features) in the original dataset, which is consistent with the description in three referenced papers.\n",
    "2. The result shows that there is no missing value in the original dataset. **=> Related to the missing value issue**.\n",
    "3. The data type of features `FUEL` and `AIRFLOW` are `object` and `float64`, respectively. According to three original papers, they are categorical features, and other features are numerical. In subsequent operations, it is possible to convert features `FUEL` and `AIRFLOW` to `category` type for further analysis.\n",
    "4. According to the statistic summary of the dataframe, the original dataset consists of six features (`SIZE`, `FUEL`, `DISTANCE`, `DESIBEL`, `AIRFLOW`, `FREQUENCY`) and one label field (`STATUS`). Checking the min, 25th percentiles, 50th percentiles, 75th percentiles and max value, there is no significant difference or gap among them. The minimum value and maximum value are consistent with those in the description of the original dataset. To be specific,\n",
    "   \n",
    "   |        | Value Range | Description | Unit | Data Type |\n",
    "   | ------ | ------ | ------ | ------ | ------ |\n",
    "   | `SIZE` | {1, 2, 3, 4, 5, 6, 7} | Fuel container size representative of flame size (1: 7cm for liquid fuels; 2: 12cm for liquid fuels; 3: 14cm for liquid fuels; 4: 16cm for liquid fuels; 5: 20cm for liquid fuels; 6: Half throttle setting for LPG; 7: Full throttle setting for LPG) | cm | numerical |\n",
    "   | `FUEL` | {'gasoline', 'thinner', 'kerosene', 'lpg'} | Fuel type (first three values are liquid fuels) | / | categorical |\n",
    "   | `DISTANCE` | [10, 190] | Distance (from flame to collimator output) | cm | numerical |\n",
    "   | `DESIBEL` | [72, 113] | Sound pressure level | dB | numerical |\n",
    "   | `AIRFLOW` | [0, 17] | Air flow generated by sound waves | m/s | numerical |\n",
    "   | `FREQUENCY` | [1, 75] | Low frequency range | Hz | numerical |\n",
    "   | `STATUS` | {0, 1} | Flame extinguished state (0: non-extinction state; 1: extinction state) | / | categorical |\n",
    "    \n",
    "5. The names of six features and one label are uppercase. In order to reduce complexity and avoid misinterpretation, I will rename them. **=> Related to the column renaming issue**.\n",
    "6. I will check whether there are duplicates. **=> Related to duplicate issue**.\n",
    "7. I will check whether there are outliers and bad data, especially for checking features like `AIRFLOW` and `FREQUENCY`. **=> Related to outliers and bad data issues**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f6208-e046-484d-bf78-6040d3a92e0a",
   "metadata": {},
   "source": [
    "##### **Task** 【Dealing with duplicates】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ab9164-fb24-4848-8f6b-4501051c8482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SIZE, FUEL, DISTANCE, DESIBEL, AIRFLOW, FREQUENCY, STATUS]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the duplicated items (rows or samples) in the original dataset\n",
    "df_raw[df_raw.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e7220-b26a-46ba-8771-f7fa16d54e84",
   "metadata": {},
   "source": [
    "**Analysis according to the above duplicate issue**:\n",
    "1. There is no duplicated row (sample) in the original dataset.\n",
    "2. To show my awareness of how to handle this issue, here is information about duplicate issues:\n",
    "   - [Definition] It is possible that data entry errors/merging of datasets led to this issue.\n",
    "   - [Methods] Identify and remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227d48d-b3e0-4aba-a975-e184945cee3a",
   "metadata": {},
   "source": [
    "##### **Task** 【Dealing with outliers and bad data】\n",
    "Using quantile() method to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48f20c0-fd43-4369-8392-21dc723b62ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature 'AIRFLOW'\n",
    "# 1) Show the 5th percentile\n",
    "df_raw['AIRFLOW'].quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aadc27f9-f379-431c-9876-f831e750c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SIZE, FUEL, DISTANCE, DESIBEL, AIRFLOW, FREQUENCY, STATUS]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Show rows whose 'AIRFLOW' is lower than the 5th percentile\n",
    "df_raw_5_airflow_quantile = df_raw[df_raw['AIRFLOW'] < df_raw['AIRFLOW'].quantile(0.05)]\n",
    "df_raw_5_airflow_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77981b91-aa2b-417b-9c6d-d3835c876859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(14.9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Show the 95th percentile\n",
    "df_raw['AIRFLOW'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3ccf16-4fe2-4e87-9235-fd7b5da6d56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>15.1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>15.2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>15.4</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>15.2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16541</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>16.1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16542</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>15.2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16543</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>15.2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>15.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>15.2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE      FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "9         1  gasoline        10       93     15.4         52       1\n",
       "10        1  gasoline        10       93     15.1         51       1\n",
       "11        1  gasoline        10       95     15.2         50       1\n",
       "12        1  gasoline        10      110     15.4         48       1\n",
       "13        1  gasoline        10      111     15.2         47       1\n",
       "...     ...       ...       ...      ...      ...        ...     ...\n",
       "16541     7       lpg        30      110     16.1         42       1\n",
       "16542     7       lpg        30      110     15.2         40       1\n",
       "16543     7       lpg        30      110     15.2         38       1\n",
       "16594     7       lpg        40      107     15.2         44       1\n",
       "16595     7       lpg        40      107     15.2         42       1\n",
       "\n",
       "[799 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Show rows whose 'AIRFLOW' is greater than the 95th percentile\n",
    "df_raw_95_airflow_quantile = df_raw[df_raw['AIRFLOW'] > df_raw['AIRFLOW'].quantile(0.95)]\n",
    "df_raw_95_airflow_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "941fd344-514b-483c-b21a-8033024cc0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15. , 15.1, 15.2, 15.4, 15.5, 15.7, 16. , 16.1, 16.3, 16.6, 17. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Check unique values of feature 'AIRFLOW'\n",
    "np.sort(df_raw_95_airflow_quantile['AIRFLOW'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2220eb7e-5be8-452d-9982-e260bc4a75dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature 'FREQUENCY'\n",
    "# 1) Show the 5th percentile\n",
    "df_raw['FREQUENCY'].quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c4a45c-c11e-49d1-9704-b4a8ffad3fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>20</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>170</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17386</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17387</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>180</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17440</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE      FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "52        1  gasoline        10       83      3.1          2       1\n",
       "53        1  gasoline        10       75      0.8          1       1\n",
       "106       1  gasoline        20       78      3.7          2       1\n",
       "107       1  gasoline        20       76      1.0          1       0\n",
       "160       1  gasoline        30       78      4.5          2       1\n",
       "...     ...       ...       ...      ...      ...        ...     ...\n",
       "17333     7       lpg       170       76      0.0          1       0\n",
       "17386     7       lpg       180       80      1.4          2       0\n",
       "17387     7       lpg       180       74      0.0          1       0\n",
       "17440     7       lpg       190       76      0.4          2       0\n",
       "17441     7       lpg       190       72      0.0          1       0\n",
       "\n",
       "[646 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Show rows whose 'FREQUENCY' is lower than the 5th percentile\n",
    "df_raw_5_frequency_quantile = df_raw[df_raw['FREQUENCY'] < df_raw['FREQUENCY'].quantile(0.05)]\n",
    "df_raw_5_frequency_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d987e1-bc88-473d-919b-f4475d0b996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Check unique values of feature 'FREQUENCY'\n",
    "np.sort(df_raw_5_frequency_quantile['FREQUENCY'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f08672e-5fcd-4f8b-bb5d-e0defe26da15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(70.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Show the 95th percentile\n",
    "df_raw['FREQUENCY'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69901c8a-b916-4c0f-9093-918ceca84619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DESIBEL</th>\n",
       "      <th>AIRFLOW</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17281</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>170</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17334</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>180</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>180</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17388</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17389</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE      FUEL  DISTANCE  DESIBEL  AIRFLOW  FREQUENCY  STATUS\n",
       "0         1  gasoline        10       96      0.0         75       0\n",
       "1         1  gasoline        10       96      0.0         72       1\n",
       "54        1  gasoline        20       96      0.0         75       0\n",
       "55        1  gasoline        20       96      0.0         72       0\n",
       "108       1  gasoline        30      106      0.0         75       0\n",
       "...     ...       ...       ...      ...      ...        ...     ...\n",
       "17281     7       lpg       170       97      0.0         72       0\n",
       "17334     7       lpg       180      104      0.0         75       0\n",
       "17335     7       lpg       180       97      0.0         72       0\n",
       "17388     7       lpg       190      104      0.0         75       0\n",
       "17389     7       lpg       190      105      0.0         72       0\n",
       "\n",
       "[646 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Show rows whose 'FREQUENCY' is greater than the 95th percentile\n",
    "df_raw_95_frequency_quantile = df_raw[df_raw['FREQUENCY'] > df_raw['FREQUENCY'].quantile(0.95)]\n",
    "df_raw_95_frequency_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5636c395-a200-4a07-a34f-5a330e8a1e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72, 75])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Check unique values of feature 'FREQUENCY'\n",
    "np.sort(df_raw_95_frequency_quantile['FREQUENCY'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db125f3-926f-4c55-a530-065384c7e8a9",
   "metadata": {},
   "source": [
    "**Analysis according to the above outliers and bad data issues**:\n",
    "1. After checking the *5th percentile* and *95th percentile*, I find that these data are not out of place. As a result, I keep these data unchanged.\n",
    "2. For other features, the min, 25th percentiles, 50th percentiles, 75th percentiles and max value are normal according to the statistic summary of the dataframe shown before.\n",
    "3. To show my awareness of how to handle this issue, here is information about outliers and bad data issues:\n",
    "   - [Definition] There is a significant difference between some data points and other observations.\n",
    "   - [Identification Methods]\n",
    "     1. Z-score \\\n",
    "        Use standard deviation to measure how far away a data point is from the mean.\n",
    "     2. IQR / Interquartile Range \\\n",
    "        Identify outliers as data points outside ```1.5 × IQR```. To be specific, ```IQR = Q3 - Q1```.\n",
    "   - [Handling Methods]\n",
    "     1. Remove rows having outliers.\n",
    "     2. Replace outliers with thresholds (upper/lower).\n",
    "     3. Apply log / square root transformations to reduce the impact of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b881004-5c82-4939-855f-ccbdb279e9db",
   "metadata": {},
   "source": [
    "##### **Task** 【Dealing with missing values】\n",
    "According to the analysis of the above statistic summary and information, there is no missing value in the original dataset.\n",
    "- To show my awareness of how to handle this issue, here is information about the missing value issue:\n",
    "   - [Definition] Missing data may occur due to errors in data collection, storage or processing.\n",
    "   - [Methods] `isnull()` or `isna()` method in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbc291-bd1e-4fc9-bf15-ad6e5065a2b4",
   "metadata": {},
   "source": [
    "##### **Task** 【Dealing with column renaming issue】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0049aac5-6be1-4baf-ae4a-a1709cee7e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Desibel</th>\n",
       "      <th>Airflow</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>2.6</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>3.2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>4.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17439</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17440</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>7</td>\n",
       "      <td>lpg</td>\n",
       "      <td>190</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17442 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Size      Fuel  Distance  Desibel  Airflow  Frequency  Status\n",
       "0         1  gasoline        10       96      0.0         75       0\n",
       "1         1  gasoline        10       96      0.0         72       1\n",
       "2         1  gasoline        10       96      2.6         70       1\n",
       "3         1  gasoline        10       96      3.2         68       1\n",
       "4         1  gasoline        10      109      4.5         67       1\n",
       "...     ...       ...       ...      ...      ...        ...     ...\n",
       "17437     7       lpg       190       86      2.2          5       0\n",
       "17438     7       lpg       190       84      2.0          4       0\n",
       "17439     7       lpg       190       80      1.5          3       0\n",
       "17440     7       lpg       190       76      0.4          2       0\n",
       "17441     7       lpg       190       72      0.0          1       0\n",
       "\n",
       "[17442 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a mapping\n",
    "mapping = {\n",
    "    'SIZE': 'Size',\n",
    "    'FUEL': 'Fuel',\n",
    "    'DISTANCE': 'Distance',\n",
    "    'DESIBEL': 'Desibel',\n",
    "    'AIRFLOW': 'Airflow',\n",
    "    'FREQUENCY': 'Frequency',\n",
    "    'STATUS': 'Status'\n",
    "}\n",
    "# rename columns\n",
    "df_raw = df_raw.rename(columns=mapping)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16e080-f99c-4c47-b3f4-d27bebb26d68",
   "metadata": {},
   "source": [
    "**Analysis according to the above column renaming issue**:\n",
    "1. Successfully renamed columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb86a18-dccf-43af-91f2-6da6f8377552",
   "metadata": {},
   "source": [
    "##### **Task** 【Check the dataframe again】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b0788f0-d431-44de-8d6b-f78f450361ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Desibel</th>\n",
       "      <th>Airflow</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "      <td>17442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.411765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.379142</td>\n",
       "      <td>6.975634</td>\n",
       "      <td>31.611111</td>\n",
       "      <td>0.497821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.750977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.773826</td>\n",
       "      <td>8.164096</td>\n",
       "      <td>4.736169</td>\n",
       "      <td>20.939149</td>\n",
       "      <td>0.500010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Size      Fuel      Distance       Desibel       Airflow  \\\n",
       "count   17442.000000     17442  17442.000000  17442.000000  17442.000000   \n",
       "unique           NaN         4           NaN           NaN           NaN   \n",
       "top              NaN  gasoline           NaN           NaN           NaN   \n",
       "freq             NaN      5130           NaN           NaN           NaN   \n",
       "mean        3.411765       NaN    100.000000     96.379142      6.975634   \n",
       "std         1.750977       NaN     54.773826      8.164096      4.736169   \n",
       "min         1.000000       NaN     10.000000     72.000000      0.000000   \n",
       "25%         2.000000       NaN     50.000000     90.000000      3.200000   \n",
       "50%         3.000000       NaN    100.000000     95.000000      5.800000   \n",
       "75%         5.000000       NaN    150.000000    104.000000     11.200000   \n",
       "max         7.000000       NaN    190.000000    113.000000     17.000000   \n",
       "\n",
       "           Frequency        Status  \n",
       "count   17442.000000  17442.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean       31.611111      0.497821  \n",
       "std        20.939149      0.500010  \n",
       "min         1.000000      0.000000  \n",
       "25%        14.000000      0.000000  \n",
       "50%        27.500000      0.000000  \n",
       "75%        47.000000      1.000000  \n",
       "max        75.000000      1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a quick statistic summary of dataframe\n",
    "df_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a437f9e2-f6b1-4e19-a566-08c726f6e2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17442 entries, 0 to 17441\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Size       17442 non-null  int64  \n",
      " 1   Fuel       17442 non-null  object \n",
      " 2   Distance   17442 non-null  int64  \n",
      " 3   Desibel    17442 non-null  int64  \n",
      " 4   Airflow    17442 non-null  float64\n",
      " 5   Frequency  17442 non-null  int64  \n",
      " 6   Status     17442 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 954.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check info of dataframe\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23530ecb-f716-47ee-a439-3efe926fdb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Desibel</th>\n",
       "      <th>Airflow</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Size, Fuel, Distance, Desibel, Airflow, Frequency, Status]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output all rows having NaN\n",
    "df_raw[df_raw.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5b4bb-b92b-48b9-8820-fe57bb1b94f6",
   "metadata": {},
   "source": [
    "##### **Task** 【Save in a file】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c24c0a1-f1a3-4bb1-9b7f-7d0a4c53dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a file with setting the label of index\n",
    "df_raw.to_csv('AEF_CLEAN.csv', index_label='Id')\n",
    "# Copy the dataframe for subsequent operations\n",
    "df_clean = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4f56e-42d7-41ff-ad40-1d10bd859590",
   "metadata": {},
   "source": [
    "### Step 3 · Data Storage\n",
    "【Step Description】\n",
    "- Centralized storage using data lakes, warehouses, or cloud storage.\n",
    "- Examples: AWS S3, Google BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445971b-437c-4ec5-872e-2e4f81ba5210",
   "metadata": {},
   "source": [
    "【Note】\n",
    "- [Information on the virtual environment]\n",
    "  1. Name: `COMP4131gpu`\n",
    "  2. Content: The virtual environment contains libraries used in this project.\n",
    "  3. Management: Utilise **Anaconda3 Client** or **Anaconda Prompt** to install and uninstall relevant libraries.\n",
    "  4. Version: `Anaconda Navigator 1.9.7`\n",
    "- Because I handle, retrieve and save all files through the **Jupyter Notebook in the virtual environment of Anaconda3**, there is no need to use data lakes, warehouses or cloud storage. **是否实现待定，去看看google bigquery这个工具**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78c8c2-8bc7-4bec-972d-ba4abaf62d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80739b7-1159-4642-88d6-972e1f1218ea",
   "metadata": {},
   "source": [
    "### Step 4 · Data Cataloging\n",
    "【Step Description】\n",
    "- Metadata management for better discoverability. **这里的实现待定** \\\n",
    "【**这一行供参考，后面删除这行文字**】Tools: Data catalog services to enable seamless data discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4878bc-c5a3-49b0-9bd9-b5e87e0b51b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb68da97-deb2-440c-ac8e-74ad96987b9f",
   "metadata": {},
   "source": [
    "## Stage 2 · Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5dd17-a969-4fb4-9466-3c7f4e58242b",
   "metadata": {},
   "source": [
    "### Step 1 · Data Exploration\n",
    "【Step Description】\n",
    "- Perform exploratory data analysis (EDA) using visualizations and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad088f-e782-43db-ace0-eaaca436ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9810503-abd0-4c39-aa0a-e77d926958f6",
   "metadata": {},
   "source": [
    "### Step 2 · Data Preprocessing (Feature Engineering)\n",
    "【Step Description】\n",
    "- Transform raw data into meaningful features for modeling. \\\n",
    "【**这一行供参考，后面删除这行文字**】Techniques: normalization, encoding categorical variables, creating derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabe124-e42d-42da-b4a2-193c94ed5d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad9096d-1e7d-4914-adc8-ac65d36fc7a1",
   "metadata": {},
   "source": [
    "### Step 3 · Data Insights\n",
    "【Step Description】\n",
    "- Generate actionable insights to understand trends and patterns. \\\n",
    "【**这一行供参考，后面删除这行文字**】Identifying correlation, seasonality, or data anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62d41b-8c48-4989-9e42-8c8d7bad4296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a550509-134f-4890-bf48-2b6157020a94",
   "metadata": {},
   "source": [
    "## Stage 3 · Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f8ce6-32f8-49eb-a9b7-c5733f8afece",
   "metadata": {},
   "source": [
    "### Step 1 · Feature Engineering\n",
    "【Step Description】\n",
    "- Improve model performance by selecting, transforming, and creating features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a242c5-276a-4e88-b775-553f5cdb3d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355bf119-4a64-43ad-9715-12bc79e71526",
   "metadata": {},
   "source": [
    "### Step 2 · Model Training\n",
    "【Step Description】\n",
    "- Train machine learning models using algorithms such as linear regression, decision trees, neural networks, etc. \\\n",
    "【**这一行供参考，后面删除这行文字**】Tools: Scikit-learn, TensorFlow, PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996e518-d5e9-4902-9afc-b57ed1f427ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "454be8c2-536d-466b-8860-ed88830198db",
   "metadata": {},
   "source": [
    "### Step 3 · Model Evaluation\n",
    "【Step Description】\n",
    "- Assess the model’s performance using metrics (e.g., accuracy, precision, recall, F1-score). \\\n",
    "Perform cross-validation to validate the model’s robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcaa43-7d60-4263-b4ec-91d4617f0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464d2550-9e4f-4c20-a75b-ac227db2ddd2",
   "metadata": {},
   "source": [
    "### Step 4 · Model Registry\n",
    "【Step Description】\n",
    "- Version control and management of models to ensure traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630c308-9350-4950-95c9-45a9d39db9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "035abe77-6c71-4d84-ae49-a0e83115027b",
   "metadata": {},
   "source": [
    "## Stage 4 · Machine Learning Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f86d2-13b7-49ed-844f-74417c2dba51",
   "metadata": {},
   "source": [
    "### Step 1 · Model Development\n",
    "【Step Description】\n",
    "- Deploy models as APIs, microservices, or edge devices. **这里的实现待定（大概率不实现），若不实现需要说明** \\\n",
    "- Deployment types: Batch, real-time, and on-device. **这里的实现待定（大概率不实现），若不实现需要说明**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d845b-59e0-438b-8f28-0a6eabc49fd1",
   "metadata": {},
   "source": [
    "### Step 2 · Model Serving\n",
    "【Step Description】\n",
    "- Serve predictions to applications or dashboards. **这里的实现待定（大概率不实现），若不实现需要说明** \\\n",
    "- Infrastructure tools: Kubernetes, Docker, AWS Lambda. **这里的实现待定（大概率不实现），若不实现需要说明**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8704a-fe6a-481d-8dae-542529a38906",
   "metadata": {},
   "source": [
    "### Step 3 · Model Monitoring\n",
    "【Step Description】\n",
    "- Track model performance in production (accuracy drift, latency). **这里的实现待定（大概率不实现），若不实现需要说明** \\\n",
    "- Monitor data for changes that can affect model performance. **这里的实现待定（大概率不实现），若不实现需要说明**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b84577-28f1-4a2c-90bc-c0d1efe56014",
   "metadata": {},
   "source": [
    "## Stage 5 · Insights Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bd1bf-b26e-43bc-9ee6-26f6a0c9b239",
   "metadata": {},
   "source": [
    "【Step Description】\n",
    "1. Influence Business Decisions:\n",
    "  - Use insights to generate reports, dashboards, and alerts.\n",
    "  - Example: Dashboards showing real-time KPIs for decision-making.\n",
    "**这里的实现待定（大概率不实现），若不实现需要说明**\n",
    "\n",
    "2. Influence Consumer Decisions:\n",
    "  - Personalize recommendations, offers, and experiences.\n",
    "  - Example: Reducing customer churn or increasing user engagement.\n",
    "**这里的实现待定（大概率不实现），若不实现需要说明**\n",
    "\n",
    "3. Serve Other Applications/Services:\n",
    "  - Integrate insights with external systems (e.g., customer service platforms, fraud detection).\n",
    "**这里的实现待定（大概率不实现），若不实现需要说明**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def001e4-fb62-41e4-b718-780c7ff70404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415cb5ac-878e-47a1-8ba0-a6b4092986ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95ed88-53c3-4f98-9efa-10363388586c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c859a96f-24d3-45f0-ada5-b25fc674ab60",
   "metadata": {},
   "source": [
    "> **Paper References**:\n",
    "> 1. Paper 1: \\\n",
    ">    [Koklu, M., & Taspinar, Y. S. (2021). Determining the extinguishing status of fuel flames with sound wave by machine learning methods. IEEE access, 9, 86207-86216, Doi: 10.1109/ACCESS.2021.3088612](https://ieeexplore.ieee.org/document/9452168)\n",
    "> 2. Paper 2: \\\n",
    ">    [Taspinar, Y. S., Koklu, M., & Altin, M. (2021). Classification of flame extinction based on acoustic oscillations using artificial intelligence methods. Case Studies in Thermal Engineering, 28, 101561.](https://www.sciencedirect.com/science/article/pii/S2214157X21007243)\n",
    "> 3. Paper 3: \\\n",
    ">    [Taspinar, Y. S., Koklu, M., & Altin, M. (2022). Acoustic-driven airflow flame extinguishing system design and analysis of capabilities of low frequency in different fuels. Fire technology, 58(3), 1579-1597.](https://link.springer.com/article/10.1007/s10694-021-01208-9)\n",
    "> \n",
    "> **Other References**:\n",
    "> 1. [Read data from excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html#pandas.read_excel)\n",
    "> 2. [Comments in Python](https://docs.python.org/3/reference/lexical_analysis.html)\n",
    "> 3. [Comments in Python](https://blog.csdn.net/weixin_69553582/article/details/136881191)\n",
    "> 4. [Official website of Pandas](https://pandas.pydata.org/docs/index.html)\n",
    "> 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b11d4-2d44-4b37-beac-89b204529f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data from two CSV files\n",
    "df_raw_dreaddit_train = pd.read_csv(\"dreaddit-train.csv\")\n",
    "df_raw_dreaddit_test = pd.read_csv(\"dreaddit-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df8e54-2327-4ed7-9e2b-3413b8897c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## check basic information about these two datasets\n",
    "# 1. generate descriptive statistics\n",
    "df_raw_dreaddit_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e80f59-9741-4fb4-b038-fe81ae4ce39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_dreaddit_train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2368ae-71c0-49cc-a067-c59977bc095b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_dreaddit_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dee007-5e51-4680-a2d9-77bce6bfe43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_dreaddit_test.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8594280-42a3-437b-afe8-79b0d0aba43e",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- [isin()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09df5d-5789-41c0-8b6e-3c8c2dfca7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. check first five rows\n",
    "df_raw_dreaddit_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688ccb3-bf72-495c-abea-645a7c4428c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_dreaddit_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f3f96-42e8-4da2-a825-972b269dd8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## select the rows (post data) posted in the subreddit \"anxiety\" or \"stress\"\n",
    "# 1. for the original training dataset from 'dreaddit'\n",
    "df_train = df_raw_dreaddit_train.loc[df_raw_dreaddit_train['subreddit'].isin(['anxiety', 'stress']), ['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'social_timestamp', 'sentiment']]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ef4a3-a532-42fe-99a7-9968977fda37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. for the original testing dataset from 'dreaddit'\n",
    "df_test = df_raw_dreaddit_test.loc[df_raw_dreaddit_test['subreddit'].isin(['anxiety', 'stress']), ['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'social_timestamp', 'sentiment']]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7781b1-603e-4572-933d-fa4d69e22afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the rows (post data) posted not in the subreddit \"anxiety\" or \"stress\", aiming at selecting posts containing and related to 'depression' to fill the datasets\n",
    "# 1. for the original training dataset from 'dreaddit'\n",
    "df_remaining_train = df_raw_dreaddit_train.loc[~df_raw_dreaddit_train['subreddit'].isin(['anxiety', 'stress']), ['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'social_timestamp', 'sentiment']]\n",
    "df_remaining_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59035ddf-09a4-4f09-9ad8-0e76ba161f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. for the original testing dataset from 'dreaddit'\n",
    "df_remaining_test = df_raw_dreaddit_test.loc[~df_raw_dreaddit_test['subreddit'].isin(['anxiety', 'stress']), ['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'social_timestamp', 'sentiment']]\n",
    "df_remaining_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3afa4-9b95-4014-b3a3-87ca6d8c1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge these two remaining datasets\n",
    "df_remaining = pd.concat([df_remaining_train, df_remaining_test], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "df_remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff47a3-cfa9-4311-90a2-e369d032edc1",
   "metadata": {},
   "source": [
    "- [contains()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82d7fe-cc38-42f0-ae9c-c8a41b332dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select posts whose contents contain several keywords from the remaining dataset \n",
    "## keywords include: \"depression\", \"depressed\", \"hopeless\", \"hopelessness\", \"sadness\", \"sad\", \"helpless\", \"helplessness\", \"disappoint\", \"disappointed\", \"disappointment\"\n",
    "keywords = [\"depression\", \"depressed\", \"hopeless\", \"hopelessness\", \"sadness\", \"sad\", \"helpless\", \"helplessness\", \"disappoint\", \"disappointed\", \"disappointment\"]\n",
    "df_remaining_depression = df_remaining[df_remaining['text'].str.contains('|'.join(keywords))]\n",
    "df_remaining_depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72b88b-ee34-4ba9-87a5-6b608f23f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge three datasets into one dataset for data preprocessing\n",
    "# 1. merge 'df_train' and 'df_test' into one dataframe\n",
    "df_1 = pd.concat([df_train, df_test], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749b1fe-e015-4995-a45d-99e3c5446448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. merge 'df_1' and 'df_remaining_depression' into one dataframe\n",
    "dataset_1 = pd.concat([df_1, df_remaining_depression], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffcabca-9831-4691-9d6d-71222db6c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. rename the 'social_timestamp'\n",
    "mapping = {\n",
    "    'id': 'id',\n",
    "    'subreddit': 'subreddit',\n",
    "    'post_id': 'post_id',\n",
    "    'text': 'text',\n",
    "    'label': 'label',\n",
    "    'confidence': 'confidence',\n",
    "    'social_timestamp': 'created_utc',\n",
    "    'sentiment': 'sentiment'\n",
    "}\n",
    "dataset_1 = dataset_1.rename(columns=mapping)\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052b03a-c31a-4947-80db-942b4025f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. check basic information about the 'dataset_1'\n",
    "dataset_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15059b6a-f0de-4bb2-b7ac-e5b354f3cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. save the final dataset as 'dataset_1'\n",
    "dataset_1.to_csv('dataset-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb35de-372b-4e60-8c60-c4119db8c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data from the CSV file\n",
    "df_raw_twitter = pd.read_csv(\"twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27074a-a52a-41d3-af96-6015639a7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check basic information about the dataset\n",
    "# 1. generate descriptive statistics\n",
    "df_raw_twitter.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf02e7-9b64-49cf-b191-8f787519116b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. check first five rows\n",
    "df_raw_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9428a-0b14-4c4d-a15a-6dd0802368cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the raw dataset\n",
    "# 1. select specific columns (features)\n",
    "df_twitter = df_raw_twitter[['id', 'conversation_id', 'tweet', 'created_at', 'date']]\n",
    "df_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c37ec-3286-45cd-87a4-0476fad361cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. add a column 'label' with all rows value 1 according to the description of the raw dataset\n",
    "df_twitter['label'] = 1\n",
    "df_twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745fb32-dfaa-4ab3-a018-14e89e6f2c75",
   "metadata": {},
   "source": [
    "**Reference**:\n",
    "- [rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91d4b5-5e38-4e73-9b1d-1485a27f4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. rename all features\n",
    "mapping = {\n",
    "    'id': 'id',\n",
    "    'conversation_id': 'post_id',\n",
    "    'tweet': 'text',\n",
    "    'created_at': 'created_utc',\n",
    "    'date': 'date', \n",
    "    'label': 'label'\n",
    "}\n",
    "df_twitter = df_twitter.rename(columns=mapping)\n",
    "df_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60e560-8f63-4c50-8a6d-686b748e2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. rearrange the order of features\n",
    "df_twitter = df_twitter[['id', 'post_id', 'text', 'label', 'created_utc', 'date']]\n",
    "df_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e45c6-3268-4eec-8800-c16f2d6cb1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select posts whose contents contain several keywords from the remaining dataset \n",
    "## keywords include: \"depression\", \"depressed\", \"hopeless\", \"hopelessness\", \"sadness\", \"sad\", \"helpless\", \"helplessness\", \"disappoint\", \"disappointed\", \"disappointment\"\n",
    "keywords = [\"depression\", \"depressed\", \"hopeless\", \"hopelessness\", \"sadness\", \"sad\", \"helpless\", \"helplessness\", \"disappoint\", \"disappointed\", \"disappointment\"]\n",
    "df_twitter_depression = df_twitter[df_twitter['text'].str.contains('|'.join(keywords), na=False)] # using na=True to handle 'NaN'\n",
    "df_twitter_depression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93b6a0-a525-4572-8caf-490bf47f7bf0",
   "metadata": {},
   "source": [
    "**References**:\n",
    "- [Merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45602c21-5eca-4787-af8f-613b9f5fcfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## merge this dataset with dataset_1 for data preprocessing\n",
    "dataset_2 = pd.concat([dataset_1, df_twitter_depression], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5fd97-dd7c-4d62-907d-ed8f8b9ba4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## rearrange the order of features\n",
    "main_dataset = dataset_2[['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'created_utc', 'date', 'sentiment']]\n",
    "main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e05fb-c8fb-4fdb-8534-029f85db20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the date into datetime type\n",
    "main_dataset['date'] = pd.to_datetime(main_dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834c562-68bf-4585-af4b-14ec34dc012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the final main dataset into a CSV file\n",
    "main_dataset.to_csv('main-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc8d7d-d4a9-4a48-97c4-8bced7cd807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76beda-d3b3-43af-b1b4-e7ae38f85cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration for PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"gOxImWE64i1kd4qjZtsUGA\",\n",
    "    client_secret=\"dQ0PfogVu7r75MOSo1tOeYMjBk8y_A\",\n",
    "    password=\"\", # my account has no password, so this field is empty\n",
    "    user_agent=\"python:depression:v0.0.1 (by /u/Efficient_Draw_2434)\",\n",
    "    username=\"u/Efficient_Draw_2434\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6fe33-85eb-4524-8f8a-88c86eee5020",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- [submission](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html)\n",
    "- [comments](https://praw.readthedocs.io/en/stable/code_overview/models/comment.html)\n",
    "- methods of subreddit\n",
    "  1. hot\n",
    "  2. new\n",
    "  3. top\n",
    "  4. rising\n",
    "  5. controversial\n",
    "  6. gilded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2ae3a-c0e5-432f-ad0a-4a5f7a6d49ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get 100 submissions and their related comments and replies about the topic of 'depression'\n",
    "# 1. initialisation\n",
    "subreddit = reddit.subreddit(\"depression\") # subreddit about depression\n",
    "subs = [] # store submissions related to 'depression'\n",
    "coms = [] # store comments related to 'depression'\n",
    "reps = [] # store replies related to 'depression'\n",
    "num_sub = 0 # collected number of submissions\n",
    "num_com = 0 # collected number of comments\n",
    "num_rep = 0 # collected number of replies\n",
    "start_time = time.perf_counter() # record consuming time\n",
    "\n",
    "# 2. get submissions\n",
    "flag_comment = False\n",
    "flag_reply = False\n",
    "hot_list = subreddit.hot(limit=100) # method of subreddit: hot\n",
    "if hot_list:\n",
    "    print(\"There exist submissions.\")\n",
    "    for submission in hot_list:\n",
    "        # select unremoved non-stickied submissions that are not related to the rules of this subreddit\n",
    "        if not submission.stickied and submission.selftext not in [\"[removed]\", \"[deleted]\"] and submission:\n",
    "            num_sub += 1\n",
    "            # contruct a dict to store the data\n",
    "            submission_info = {\n",
    "                'id': submission.id,\n",
    "                'subreddit': 'depression',\n",
    "                'post_id': submission.id,\n",
    "                # 'name': submission.name, # fullname of the submission\n",
    "                # 'title': submission.title, # title of the submission\n",
    "                'text': submission.selftext, # content of the submission\n",
    "                # 'num_comments': submission.num_comments, # number of comments in this submission\n",
    "                # 'score': submission.score, # the number of upvotes for the submission\n",
    "                'created_utc': submission.created_utc, # created time\n",
    "                # 'upvote_ratio': submission.upvote_ratio, # the percentage of upvotes from all votes on the submission\n",
    "                # 'author_id': None, # info about the author of this comment\n",
    "                # 'author_username': None, # info about the author of this comment\n",
    "                # 'author_descriptions': None # info about the author of this comment\n",
    "            }\n",
    "            # # get info about the author of this submission\n",
    "            # if submission.author:\n",
    "            #     if submission.author.name not in [\"[removed]\", \"[deleted]\"]:\n",
    "            #         # if not submission.author.is_suspended:\n",
    "            #         #     submission_info['author_id'] = submission.author.id\n",
    "            #         submission_info['author_username'] = submission.author.name\n",
    "            #         # check whether this author has subreddits\n",
    "            #         # if submission.author.subreddit and hasattr(submission.author, \"subreddit\"):\n",
    "            #         #     submission_info['author_descriptions'] = submission.author.subreddit.public_description\n",
    "            # append the submission\n",
    "            subs.append(submission_info)\n",
    "        \n",
    "            # 3. get comments\n",
    "            submission.comments.replace_more(limit=None) # get all comments\n",
    "            com_list = submission.comments\n",
    "            if com_list:\n",
    "                flag_comment = True\n",
    "                for comment in com_list:\n",
    "                    # select unremoved comments\n",
    "                    if comment and comment.body and comment.body not in [\"[removed]\", \"[deleted]\"]:\n",
    "                        num_com += 1\n",
    "                        # contruct a dict to store the data\n",
    "                        comment_info = {\n",
    "                            'id': comment.id,\n",
    "                            'subreddit': 'depression',\n",
    "                            'post_id': comment.id,\n",
    "                            # 'submission_id': None, # id of the submission this comment belongs to\n",
    "                            # 'submission_title': None, # title of the submission this comment belongs to\n",
    "                            'text': comment.body, # content of the comment\n",
    "                            # 'link_id': comment.link_id, # the submission ID that the comment belongs to\n",
    "                            # 'score': comment.score, # the number of upvotes for the comment\n",
    "                            'created_utc': comment.created_utc, # created time\n",
    "                            # 'author_id': None, # info about the author of this comment\n",
    "                            # 'author_username': None, # info about the author of this comment\n",
    "                            # 'author_descriptions': None # info about the author of this comment\n",
    "                        }\n",
    "                        # # get info about the submission this comment belongs to\n",
    "                        # if comment.submission:\n",
    "                        #     # comment_info['submission_id'] = comment.submission.id\n",
    "                        #     comment_info['submission_title'] = comment.submission.title\n",
    "                        # # get info about the author of this comment\n",
    "                        # if comment.author:\n",
    "                        #     if comment.author.name not in [\"[removed]\", \"[deleted]\"]:\n",
    "                        #         # if not comment.author.is_suspended:\n",
    "                        #         #     comment_info['author_id'] = comment.author.id\n",
    "                        #         comment_info['author_username'] = comment.author.name\n",
    "                        #         # check whether this author has subreddits\n",
    "                        #         # if comment.author.subreddit and hasattr(comment.author, \"subreddit\"):\n",
    "                        #         #     comment_info['author_descriptions'] = comment.author.subreddit.public_description\n",
    "                        # append the comment\n",
    "                        coms.append(comment_info)\n",
    "        \n",
    "                        # 4. get replies\n",
    "                        comment.replies.replace_more(limit=None) # get all replies\n",
    "                        rep_list = comment.replies\n",
    "                        if rep_list:\n",
    "                            flag_reply = True\n",
    "                            for reply in rep_list:\n",
    "                                # select unremoved replies\n",
    "                                if reply and reply.body and reply.body not in [\"[removed]\", \"[deleted]\"]:\n",
    "                                    num_rep += 1\n",
    "                                    # contruct a dict to store the data\n",
    "                                    reply_info = {\n",
    "                                        'id': reply.id,\n",
    "                                        'subreddit': 'depression',\n",
    "                                        'post_id': reply.id,\n",
    "                                        # 'submission_id': None, # id of the submission this reply belongs to\n",
    "                                        # 'submission_title': None, # title of the submission this reply belongs to\n",
    "                                        'text': reply.body, # content of the comment\n",
    "                                        # 'link_id': reply.link_id, # the submission ID that the comment belongs to\n",
    "                                        # 'score': reply.score, # the number of upvotes for the comment\n",
    "                                        'created_utc': reply.created_utc, # created time\n",
    "                                        # 'author_id': None, # info about the author of this reply\n",
    "                                        # 'author_username': None, # info about the author of this reply\n",
    "                                        # 'author_descriptions': None # info about the author of this reply\n",
    "                                    }\n",
    "                                    # # get info about the submission this reply belongs to\n",
    "                                    # if reply.submission:\n",
    "                                    #     # reply_info['submission_id'] = reply.submission.id\n",
    "                                    #     reply_info['submission_title'] = reply.submission.title\n",
    "                                    # # get info about the author of this reply\n",
    "                                    # if reply.author:\n",
    "                                    #     if reply.author.name not in [\"[removed]\", \"[deleted]\"]:\n",
    "                                    #         # if not reply.author.is_suspended:\n",
    "                                    #         #     reply_info['author_id'] = reply.author.id\n",
    "                                    #         reply_info['author_username'] = reply.author.name\n",
    "                                    #         # check whether this author has subreddits\n",
    "                                    #         # if reply.author.subreddit and hasattr(reply.author, \"subreddit\"):\n",
    "                                    #         #     reply_info['author_descriptions'] = reply.author.subreddit.public_description\n",
    "                                    # append the reply\n",
    "                                    reps.append(reply_info)\n",
    "else:\n",
    "    print(\"No submission exists.\")\n",
    "if not flag_comment:\n",
    "    print(\"No comment exists.\")\n",
    "if not flag_reply:\n",
    "    print(\"No reply exists.\")\n",
    "\n",
    "# 5. output-related information\n",
    "end_time = time.perf_counter() # record consuming time\n",
    "print(\"The data collection procedure consumes: \", end_time - start_time, \" seconds.\")\n",
    "print(\"\\nThe list of submissions: \\n\", subs)\n",
    "print(\"\\nThe list of comments: \\n\", coms)\n",
    "print(\"\\nThe list of replies: \\n\", reps)\n",
    "print(\"\\nNumber of submissions: \", num_sub)\n",
    "print(\"Number of comments: \", num_com)\n",
    "print(\"Number of replies: \", num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1b6cb-9984-4fea-8cb1-c4198a9b9737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## convert submissions, comments and replies into 'dataframe'\n",
    "# 1. submissions\n",
    "df_subs = pd.DataFrame(subs)\n",
    "df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00f49d-bdf3-4292-865d-e89ed1e8e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five rows of df_subs\n",
    "df_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c57447-6537-45c3-8d30-07ffe646e62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. comments\n",
    "df_coms = pd.DataFrame(coms)\n",
    "df_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf97272-37ed-4737-b544-a730e05f4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five rows of df_coms\n",
    "df_coms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799144e3-7102-412a-8df6-b094cf291ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. replies\n",
    "df_reps = pd.DataFrame(reps)\n",
    "df_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb731b4-bcec-4596-a4ca-f858f6615261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five rows of df_reps\n",
    "df_reps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877651e-d51c-4643-a119-21ba48dffade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## merge into one dataframe\n",
    "# 1. concat dataframe of comments and replies\n",
    "df_coms_reps = pd.concat([df_coms, df_reps], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "# 2. merge it and dataframe of submission\n",
    "test_dataset = pd.concat([df_subs, df_coms_reps], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023333b-ce15-47f2-979b-5b59d54fa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store data as a CSV file\n",
    "test_dataset.to_csv('test-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3230e-da58-4892-bfde-7850414ac1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## explore the dataset to find potential issues\n",
    "# 1. print the shape\n",
    "print(test_dataset.shape)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93ce2c-ee42-4e9b-aa6a-294dce6c61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Show the description of all columns\n",
    "test_dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98c87d-a9f5-4498-8c39-1aa472660a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. check whether there exist any missing value\n",
    "test_dataset[test_dataset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e23e81-9a15-4b4d-8911-46b53310b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Print the info of the main dataset\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e066717-2fca-4b26-9485-fcb6cfa3a1ff",
   "metadata": {},
   "source": [
    "The result of the description of the `DataFrame` shows:\n",
    "- **Because the data is collected from the API, it is possible to have different texts with different frequencies.** The value with the highest frequency of column 'text' is 'Count me in' with a frequency of 2.\n",
    "- **Missing Value Issue**: The test dataset lacks three columns: 'label', 'confidence' and 'sentiment'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a6e08-a368-40ad-ab8c-24c2c2ad5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with duplicates\n",
    "# 1. show the duplicated items (rows or samples) in the original dataset\n",
    "test_dataset[test_dataset.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cdc6d-5336-4e87-958d-d978c0d3d756",
   "metadata": {},
   "source": [
    "- **Because the data is collected from the API, it is possible to have different texts with different frequencies. The code here is used for 'Count me in' example.** \\\n",
    "  The value with the highest frequency of column 'text' is 'Count me in' with a frequency of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60f59a-786c-4c10-82dc-8baf01f0ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. For the above phenomenon, check whether they are posted by one person\n",
    "test_dataset[test_dataset['text'] == 'Count me in']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706dd11-a0f9-4483-b9fb-c9dcea10fba3",
   "metadata": {},
   "source": [
    "If there are duplicated texts 'Count me in', it doesn't mean that there exists a problem. In reality, it is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd0964-0edb-4722-a209-4ec572b9b29e",
   "metadata": {},
   "source": [
    "- **Missing Value Issue**: The test dataset lacks column 'confidence'. \\\n",
    "  Because the origin dataset from Reddit doesn't have any value in this column, it is a good idea to replace the missing values with the average of the subgroup whose data was collected from Kaggle and the subreddit is 'anxiety'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea3b3f-de0a-4ddc-a37a-4d99f9953bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column 'confidence'\n",
    "# 1. get the average of the subgroup in the main dataset\n",
    "mean_value = main_dataset.loc[main_dataset['subreddit'] == 'depression', 'confidence'].values[0]\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c222ab-a415-413c-af02-b86f1e680c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. iterate over all rows\n",
    "test_dataset['confidence'] = 0.0\n",
    "for i, row in test_dataset[:].iterrows():\n",
    "   test_dataset.loc[i, 'confidence'] = mean_value\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d020d-2592-4768-826a-4bbc3e510124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. show rows having 'NaN'\n",
    "test_dataset[test_dataset['confidence'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3eb912-95ef-4d7f-a4fb-9689ceb1f7cb",
   "metadata": {},
   "source": [
    "- **Missing Value Issue**: The test dataset lacks column 'label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776fe55-d770-4b50-a01b-17b9561a4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column 'label'\n",
    "# 1. imputation\n",
    "test_dataset['label'] = -1\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51d5ab-e720-4709-ae8f-1cb1cb1aab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. show rows having 'NaN'\n",
    "test_dataset[test_dataset['label'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef673f-3bdb-439b-a681-c1e36caa3377",
   "metadata": {},
   "source": [
    "- **Missing Value Issue**: The test dataset lacks column 'sentiment'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb4ca8-95ad-4629-8a2c-2555079fdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column 'label'\n",
    "# 1. imputation\n",
    "test_dataset['sentiment'] = 0.0\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ffe77-df4c-4d9f-9bc1-dfde34734e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. show rows having 'NaN'\n",
    "test_dataset[test_dataset['sentiment'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866f209-2fd6-4fb4-852d-60dd7502833e",
   "metadata": {},
   "source": [
    "- **Creating a new column 'date'**. \\\n",
    "  To keep consistent with the field structure of `main_dataset`, it is necessary to add the 'date' column, whose value is converted from the 'created_utc' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e296a6-54c3-4afc-b3a8-fb9f6ddfc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column named 'date'\n",
    "# 1. check info\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66834c16-f906-4e87-907f-e778f6d6a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. show rows having 'NaN'\n",
    "test_dataset[test_dataset['created_utc'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a3a18-2adc-4963-9455-dbefee3cfe7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. iterate over all rows\n",
    "for i, row in test_dataset[:].iterrows():\n",
    "    # 1) get current row's UTC timestamp\n",
    "    timestamp = test_dataset.loc[i, 'created_utc']\n",
    "    # print(f\"orginal timestamp: {timestamp}\")\n",
    "    # 2) convert to date\n",
    "    obj = datetime.utcfromtimestamp(timestamp)\n",
    "    # 3) formatted as yyyy-MM-dd HH:mm:ss\n",
    "    date = obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # print(f\"formatted date: {date}\\n\")\n",
    "    # 4) save the formatted date\n",
    "    test_dataset.loc[i, 'date'] = date\n",
    "# conver the date into datetime type\n",
    "test_dataset['date'] = pd.to_datetime(test_dataset['date'])\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e809e3-52b4-40a7-bcf7-fbdea3dd0b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. rearrange the order of features\n",
    "test_dataset = test_dataset[['id', 'subreddit', 'post_id', 'text', 'label', 'confidence', 'created_utc', 'date', 'sentiment']]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78423c29-106f-484c-9f7e-6c87b8d1162f",
   "metadata": {},
   "source": [
    "**Final Check and Save Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40175ad-2be5-4789-9642-2ef303cf0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check whether there exist any missing value\n",
    "test_dataset[test_dataset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a64d9-f5c6-4b03-88d6-21a18c021f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the preprocessed test dataset\n",
    "test_dataset.to_csv('preprocessed-test-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95d80a-3aa8-41f0-b740-43422345a580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## explore the dataset to find potential issues\n",
    "# 1. print the shape\n",
    "print(global_dataset.shape)\n",
    "global_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4410b-17ab-485f-83e2-7bc3d30a69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. show the description of all columns\n",
    "global_dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d909c6c-c21e-4e28-b292-c1d83e27c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. check whether there are missing values and other issues\n",
    "print(global_dataset[global_dataset.isna().any(axis=1)].shape)\n",
    "global_dataset[global_dataset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe3313-cb5c-4bce-bcb2-1cf60ece356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. check whether other columns () have missing values\n",
    "print(global_dataset[global_dataset[['country/region', 'year', 'schizophrenia_disorders_rate', \n",
    "                                     'bipolar_disorders_rate', 'eating_disorders_rate', 'anxiety_disorders_rate',\n",
    "                                     'drug_disorders_rate', 'depression_disorders_rate', \n",
    "                                     'alcohol_disorders_rate']].isna().any(axis=1)].shape)\n",
    "global_dataset[global_dataset[['country/region', 'year', 'schizophrenia_disorders_rate',\n",
    "                               'bipolar_disorders_rate', 'eating_disorders_rate', 'anxiety_disorders_rate',\n",
    "                               'drug_disorders_rate', 'depression_disorders_rate', \n",
    "                               'alcohol_disorders_rate']].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2976e1-2356-434c-9640-c03388746f67",
   "metadata": {},
   "source": [
    "The result of the description of the `DataFrame` shows:\n",
    "- **Missing Value Issue**: The result shows that 980 rows are missing the unicode for the country/region. **However, this feature is not the key feature of the task, we can just replace them with 'unknown'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9cdc8-57b8-44fb-877d-4c0b0d7dcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with duplicates\n",
    "# 1. show the duplicated items (rows or samples) in the original dataset\n",
    "global_dataset[global_dataset.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f116b-e6f2-4d31-935b-a1c90a8de0ba",
   "metadata": {},
   "source": [
    "The result shows that there is no duplicated row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a7806-6eaa-43ea-8ff5-d627d7499167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Dealing with missing values\n",
    "# 1. show rows having 'NaN'\n",
    "global_dataset[global_dataset['unicode'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24ecb3-0752-41b0-91b2-58d0e0d896f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. iterate over the rows where 'unicode' is 'NaN' and replace these unicode with 'unknown'\n",
    "for i, row in global_dataset[global_dataset['unicode'].isna()].iterrows():\n",
    "    global_dataset.loc[i, 'unicode'] = 'unknown'\n",
    "global_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efc32d-e86e-4856-b1e1-a2b7dcfa80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. check again\n",
    "global_dataset[global_dataset['unicode'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0ce34-72b7-4a2f-baa7-eb708eeaa301",
   "metadata": {},
   "source": [
    "Successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd68b3-8a97-4818-ad8f-374c1a058095",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with outliers and bad data\n",
    "# According to the description of all columns, there is no unreasonable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449824c-4018-4d0c-9a84-7c25aa03c677",
   "metadata": {},
   "source": [
    "**Final Check and Save Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe54a0-f79c-4926-bd10-a03bb66dd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check whether there exist any missing value\n",
    "global_dataset[global_dataset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002025a-0686-4a75-938e-5b399da0b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the preprocessed main dataset\n",
    "global_dataset.to_csv('preprocessed-global-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1b425-95b7-4bac-b070-dbcce7e7e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check info of the main dataset and test dataset\n",
    "# 1. main dataset\n",
    "main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75828399-3b85-425d-a060-110040887cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. test dataset\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621376b-5a1f-4117-b5f8-08c47f88adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. merge two datasets\n",
    "final_social_dataset = pd.concat([main_dataset, test_dataset], axis=0).reset_index(drop=True) # axis=0: concat two tables vertically\n",
    "final_social_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3733c-bbd6-4b09-a584-7a61ad87ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. check info \n",
    "final_social_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472d598-a536-48af-9211-131500f94a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. check whether there exist any missing value\n",
    "final_social_dataset[final_social_dataset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc58a4-0e39-4931-8e84-6d6dc5a5b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy the main dataset\n",
    "nltk_main_dataset = final_social_dataset.copy()\n",
    "nltk_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d9878-fc4d-4e71-ad3f-46c03f7ecf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "# 1. get English stop words\n",
    "stop_words = stopwords.words('english')\n",
    "print(f\"English stop words include: \\n{stop_words}\")\n",
    "# 2. create an instance of TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd085d2-6477-4e66-b0cf-2f09d6b76d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. iterate over all rows\n",
    "# 1) create a variable for counting overall work frequency distribution\n",
    "overall_tokens = []\n",
    "for i, row in nltk_main_dataset[:].iterrows():\n",
    "    print(f\"index: {i} \\n1) id: {nltk_main_dataset.loc[i, 'id']} \\n2) text: \\n{row['text']}\")\n",
    "    # 2) lowercase\n",
    "    lower_text = row['text'].lower()\n",
    "    # print(f\"3) lower: \\n{lower_text}\")\n",
    "    # 3) remove HTML tags\n",
    "    soup = BeautifulSoup(lower_text, 'html.parser')\n",
    "    removed_html_text = soup.get_text()\n",
    "    # print(f\"4) remove html texts: \\n{removed_html_text}\")\n",
    "    # 4) remove punctuation\n",
    "    #    str.maketrans: create a character Map\n",
    "    #      1st param: characters to be replaced\n",
    "    #      2nd param: characters after replacement\n",
    "    #      3rd param: characters to be deleted\n",
    "    # removed_punctuation_text = removed_html_text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    removed_punctuation_text = removed_html_text.replace('’', '\\'') # this punctuation has a really high frequency\n",
    "    # print(f\"5) remove punctuation: \\n{removed_punctuation_text}\")\n",
    "    # 5) tokenize\n",
    "    # tokens = nltk.word_tokenize(removed_html_text, language='english')\n",
    "    tokens = tknzr.tokenize(removed_punctuation_text)\n",
    "    # print(f\"6) tokens: \\n{tokens}\")\n",
    "    # 6) remove stop words\n",
    "    non_stopword_tokens = [token for token in tokens if token not in stop_words]\n",
    "    print(f\"3) tokens without stop words: \\n{non_stopword_tokens}\\n\")\n",
    "    # 7) append items from iterable to the end of the array\n",
    "    overall_tokens.extend(non_stopword_tokens)\n",
    "# 8) show preprocessed dataframe\n",
    "nltk_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8d172-ce1e-48b1-960f-7128201161b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a self-defined depression dictionary based on high-frequency words\n",
    "# 1. get the word frequency distribution (without considering punctuation)\n",
    "overall_tokens = [token for token in overall_tokens if token not in string.punctuation]\n",
    "fdist = FreqDist(token for token in overall_tokens)\n",
    "print(f\"word frequency distribution of all tokens: \\n{fdist.pformat(maxlen=200)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d571087-d2a2-4288-bc60-45405885d26d",
   "metadata": {},
   "source": [
    "According to the above frequency dictionary, **I chose tokens with a frequency larger than 90 to construct a self-defined depression dictionary based on high-frequency words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace3dbf-b070-4436-982e-acdebf3457f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. select depression-related words manually\n",
    "extra_depression_list = [\n",
    "    \"anxiety\", \"life\", \"want\", \"can't\", \"never\", \"depression\",  \n",
    "    \"need\", \"bad\", \"sad\", \"nothing\", \"hard\", \"depressed\", \"anxious\", \n",
    "    \"mental\", \"panic\", \"worse\"\n",
    "]\n",
    "# extra_depression_list = [\n",
    "#     \"anxiety\", \"help\", \"life\", \"can't\", \"depression\", \"never\", \n",
    "#     \"sad\", \"bad\", \"anxious\", \"need\", \"mental\", \"hard\", \"health\", \n",
    "#     \"nothing\", \"depressed\", \"attacks\", \"issues\"\n",
    "# ]\n",
    "extra_depression_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e4b4d-8554-4cc1-9f25-be2b4673441f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. compute a strength score for each depression-related word selected above\n",
    "extra_depression_dict = {}\n",
    "for word in extra_depression_list:\n",
    "    # 1) create the analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    # 2) get the score\n",
    "    score = sia.lexicon.get(word, 0) # if the word is not in the sia's dictionary, then return 0\n",
    "    print(f\"The sentiment score for '{word}' is: {score}\")\n",
    "    # 3) construct a key-value pair\n",
    "    if score != 0: # in the sia's dictionary\n",
    "        extra_depression_dict[word] = score\n",
    "    else: # set a default strength score\n",
    "        extra_depression_dict[word] = -0.1\n",
    "extra_depression_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d34cc8-fce4-4012-b1bc-4609a722a6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## VADER sentiment analysis\n",
    "# 1. iterate over all rows and call the method\n",
    "nltk_main_dataset['pred_label'] = np.nan\n",
    "nltk_main_dataset['pred_sentiment'] = np.nan\n",
    "for i, row in nltk_main_dataset[:].iterrows():\n",
    "    print(f\"index: {i} \\n1) id: {nltk_main_dataset.loc[i, 'id']} \\n2) subreddit: {nltk_main_dataset.loc[i, 'subreddit']} \\n3) text: \\n{row['text']}\")\n",
    "    # 1) create the analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    # 2) extend the dictionary of the analyzer\n",
    "    sia.lexicon.update(extra_depression_dict)\n",
    "    # 3) compute the sentiment scores for sentiment strength based on the input text\n",
    "    sentiment_scores = sia.polarity_scores(row['text'])\n",
    "    # 4) output details of the score\n",
    "    sorted_sentiment_scores = sorted(sentiment_scores)\n",
    "    for j in sorted_sentiment_scores:\n",
    "        print('4) {0}: {1}; '.format(j, sentiment_scores[j]), end='')\n",
    "    print(\"\\n\")\n",
    "    # 5) classify by confidence score\n",
    "    if sentiment_scores['compound'] < 0:\n",
    "        nltk_main_dataset.loc[i, 'pred_label'] = 1 # create a new column\n",
    "    else:\n",
    "        nltk_main_dataset.loc[i, 'pred_label'] = 0 # create a new column\n",
    "    # 6) store the confidence scores and label\n",
    "    nltk_main_dataset.loc[i, 'pred_sentiment'] = sentiment_scores['compound'] # create a new column\n",
    "nltk_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3173f8-18f5-489e-a343-9f312cddbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. compare the sentiment scores with the real sentiment scores (including data from all subreddits, except for the 'depression' subreddit)\n",
    "eval_main_dataset = nltk_main_dataset[nltk_main_dataset['subreddit'] != 'depression'].copy()\n",
    "pd.DataFrame({'real_sentiment': eval_main_dataset['sentiment'], 'pred_sentiment': eval_main_dataset['pred_sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0f781-bab0-4d79-a686-5991bcfd2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. compute the accuracy of the result\n",
    "cnt_sentiment = ((eval_main_dataset['sentiment'] > 0) == (eval_main_dataset['pred_sentiment'] > 0)).sum()\n",
    "acc_sentiment = cnt_sentiment / len(eval_main_dataset)\n",
    "print(f\"The consistent amount of data is: {cnt_sentiment} and overall amount of data is: {len(eval_main_dataset)}.\")\n",
    "print(f\"The accuracy of the result is: {acc_sentiment}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c22f5-91df-46cb-b95a-320a4e3bf383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. compare the labels with the real labels (including data from all subreddits, except for the 'depression' subreddit)\n",
    "pd.DataFrame({'real_label': eval_main_dataset['label'], 'pred_label': eval_main_dataset['pred_label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78084470-af4c-4cda-8f63-c6b9eabec6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. compute the accuracy of the result\n",
    "cnt_label = (eval_main_dataset['label'] == eval_main_dataset['pred_label']).sum()\n",
    "acc_label = cnt_label / len(eval_main_dataset)\n",
    "print(f\"The consistent amount of data is: {cnt_label} and overall amount of data is: {len(eval_main_dataset)}.\")\n",
    "print(f\"The accuracy of the result is: {acc_label}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a47bb-c342-4ba8-b175-f0dcc3d9d4cf",
   "metadata": {},
   "source": [
    "The result shows that for data collected from the first dataset (whose data is collected form the Reddit), the NLTK can output the accuracy of almost 69.01%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92d2b0-d1ee-4f72-a044-f2d9c7da12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Result analysis\n",
    "# 1. show the word cloud\n",
    "# 1) read the mask image\n",
    "mask_picture = np.array(Image.open(os.path.join(os.getcwd(), \"people.png\"))) # os.getcwd(): get current directory\n",
    "# 2) create an instance of the WordCloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=mask_picture, \n",
    "               width=800, height=600, stopwords=stop_words, \n",
    "               contour_width=1, contour_color='steelblue')\n",
    "# 3) concat all tokens into a string\n",
    "wc_text = ' '.join(overall_tokens)\n",
    "# 4) generate the word cloud\n",
    "wc.generate(wc_text)\n",
    "# 5) save to a file\n",
    "wc.to_file(os.path.join(os.getcwd(), \"word_cloud.png\"))\n",
    "# 6) show the word cloud\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.title(\"Word Cloud of keywords\")\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0c1c8-d56b-40e4-8c58-02f1e64920ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. create a heatmap\n",
    "# 1) use keywords that appear in the Data Collection Part\n",
    "depression_keywords = [\"depression\", \"depressed\", \"hopeless\", \"hopelessness\", \"sadness\", \"sad\", \"helpless\", \"helplessness\", \"disappoint\", \"disappointed\", \"disappointment\"]\n",
    "# 2) copy the main_dataset\n",
    "analyse_main_dataset = nltk_main_dataset.copy()\n",
    "analyse_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae0fef-6eec-42c2-9f28-8ab38ed3a265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3) check info\n",
    "analyse_main_dataset.info()\n",
    "analyse_main_dataset['pred_label'] = analyse_main_dataset['pred_label'].astype(int)\n",
    "# 4) extract year, month and day\n",
    "analyse_main_dataset['year'] = analyse_main_dataset['date'].dt.year\n",
    "analyse_main_dataset['month'] = analyse_main_dataset['date'].dt.month\n",
    "analyse_main_dataset['day'] = analyse_main_dataset['date'].dt.day\n",
    "analyse_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca903808-6575-42dc-b6af-8512ff044c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_main_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8ef73-2fd6-406e-8bf8-0ec1c706c329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5) construct a dataframe to draw the heatmap\n",
    "# select rows mentioning depression-related keywords\n",
    "#   case=False: case insensitive\n",
    "#   na=False: not fill missing values\n",
    "mention_main_dataset = analyse_main_dataset[analyse_main_dataset['text'].str.contains('|'.join(depression_keywords), case=False, na=False)]\n",
    "mention_main_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10426a41-cb51-4217-8925-6f89506b17ab",
   "metadata": {},
   "source": [
    "- [groupby()](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean)\n",
    "- [reset_index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index)\n",
    "- [pivot()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot)\n",
    "- [fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna)\n",
    "- [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html#seaborn.heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8f245-2c9f-4d7a-a353-619140bda0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use groupby() to group by year and month\n",
    "heatmap_data = mention_main_dataset.groupby(['year', 'month']).size()\n",
    "heatmap_data = heatmap_data.reset_index(name='num_keywords')\n",
    "heatmap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40c4dc-0e51-4052-9b1c-a7b26407a188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the dataframe\n",
    "sorted_heatmap_data = heatmap_data.sort_values(by=['year', 'month'], ascending=True)\n",
    "sorted_heatmap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447cdab-4b2d-4d55-a4a8-589a1da06c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the dataframe\n",
    "sorted_heatmap_data = sorted_heatmap_data.pivot(index='year', columns='month', values='num_keywords')\n",
    "sorted_heatmap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57aa6f-b1fb-43d8-9195-c8f4ba34c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NaN with 0\n",
    "sorted_heatmap_data = sorted_heatmap_data.fillna(0)\n",
    "sorted_heatmap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc88b30-2715-4814-96d9-a2ba9d56b5fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(data=sorted_heatmap_data, annot=True, fmt=\".1f\", linewidth=.5, cbar=True, cmap=\"crest\")\n",
    "ax.set(xlabel=\"month\", ylabel=\"year\")\n",
    "ax.xaxis.tick_top()\n",
    "# set title and save\n",
    "plt.title(\"Heatmap of depression mentioned by year and month\")\n",
    "plt.savefig('heatmap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7b0a7-8174-42df-a0d9-2a11ef8b3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. correlation analysis\n",
    "# 1) use groupby() to group by year\n",
    "num_keywords_data = mention_main_dataset.groupby(['year']).size()\n",
    "num_keywords_data = num_keywords_data.reset_index(name='num_keywords')\n",
    "num_keywords_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15796584-3d83-4e55-aecf-0e7b5abfcc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2) compute the global average annual prevalence of depression from the global mental health dataset\n",
    "average_prevalence_depression = global_dataset.groupby('year')[['schizophrenia_disorders_rate', 'bipolar_disorders_rate', \n",
    "                                                                'eating_disorders_rate', 'anxiety_disorders_rate', \n",
    "                                                                'drug_disorders_rate', 'depression_disorders_rate', \n",
    "                                                                'alcohol_disorders_rate']].mean()\n",
    "average_prevalence_depression = average_prevalence_depression.reset_index(names=\"year\")\n",
    "average_prevalence_depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3d40a-0e33-465e-83d0-8991c10c4914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3) integrate two dataframes into one dataframe\n",
    "regression_data = pd.merge(num_keywords_data, average_prevalence_depression, on='year', how='outer')\n",
    "regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe84ca-d697-4267-a5ee-f3bf23f707c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) consider rows without missing values\n",
    "# here, I don't reset indices, because it can help find the corresponding year\n",
    "handled_regression_data = regression_data.dropna()\n",
    "handled_regression_data = handled_regression_data[['num_keywords', 'schizophrenia_disorders_rate', 'bipolar_disorders_rate',\n",
    "                                   'eating_disorders_rate', 'anxiety_disorders_rate', 'drug_disorders_rate', \n",
    "                                   'depression_disorders_rate', 'alcohol_disorders_rate']]\n",
    "handled_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ee229-43f2-4274-b224-248255464882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) calculate the correlation\n",
    "correlation = handled_regression_data.corr(numeric_only=True)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38344f9-827c-4a3c-b20d-af8db8f8322e",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- Each variable and itself have a perfect positive linear correlation.\n",
    "- Variables `num_keywords` and `depression_disorders_rate` have a correlation coefficient of -0.356597. This means that **there is a moderate negative correlation** between these two variables. **As the number of keywords mentioned in the social media platforms increases, the rate of depression will decrease.**\n",
    "- Variables `num_keywords` and `anxiety_disorders_rate` have a correlation coefficient of -0.739638. Variables `num_keywords` and `alcohol_disorders_rate` have a correlation coefficient of -0.761096. These mean that **there are strong negative correlations** between these pairs of two variables.\n",
    "- Variables `num_keywords` and `schizophrenia_disorders_rate` have a correlation coefficient of 0.687847. Variables `num_keywords` and `bipolar_disorders_rate\t` have a correlation coefficient of 0.703226. Variables `num_keywords` and `eating_disorders_rate` have a correlation coefficient of 0.675158. Variables `num_keywords` and `drug_disorders_rate` have a correlation coefficient of 0.693156. These mean that **there are strong positive correlations** between these pairs of two variables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9db34-a4d4-402e-b2fb-b0fe79b0350e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6) create the heatmap for correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data=correlation, annot=True, fmt=\".2f\", linewidth=.5, cbar=True, vmin=-1.0, vmax=1.0)\n",
    "plt.title(\"Correlation between number of keywords and disorders rates\")\n",
    "plt.subplots_adjust(top=0.95, bottom=0.3, left=0.25, right=0.95, hspace=0.1, wspace=0.1)\n",
    "plt.savefig('correlation.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd84b85-a471-4f30-ae2d-511ec15edcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) calculate the pearson correlation and p-value\n",
    "pearson_coef, p_value = stats.pearsonr(handled_regression_data['num_keywords'], \n",
    "                                       handled_regression_data['depression_disorders_rate'])\n",
    "print(f\"The Pearson Correlation Coefficient is: {pearson_coef} with a p-value of P = {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1d756-b253-484c-8283-d9724e148d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. draw a line chart\n",
    "# 1) select data\n",
    "line_data = regression_data[['year', 'num_keywords', 'depression_disorders_rate']].copy()\n",
    "line_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271f51a-3604-4402-b351-b83a0b34041c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2) imputate the missing values\n",
    "line_data = line_data.fillna(0)\n",
    "line_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933b8c4-b68e-4425-ab7f-0aae8abec268",
   "metadata": {},
   "source": [
    "- [plt](https://matplotlib.org/stable/api/pyplot_summary.html)\n",
    "- [plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot)\n",
    "- [legend](https://matplotlib.org/stable/api/legend_api.html#module-matplotlib.legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2ccf5-dc46-4e98-bd66-8d535a0d5a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3) draw the chart (left axis)\n",
    "plt.figure(figsize=(10, 6))\n",
    "line1 = plt.plot(line_data['year'], line_data['num_keywords'], 'g^-', label='Number of keywords [having data between 2013 and 2025]') # return a list\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average number of keywords')\n",
    "# 4) draw the chart (right axis)\n",
    "ax2 = plt.twinx() # share the first axis\n",
    "line2 = ax2.plot(line_data['year'], line_data['depression_disorders_rate'], 'ro-', label='Depression disorders rate (%) [having data between 1990 and 2017]') # return a list\n",
    "ax2.set_ylabel('Average depression disorders rate (%)')\n",
    "# 5) other settings of the line chart\n",
    "plt.title(\"Average number of keywords and depression disorders rate throughout years\")\n",
    "lines = [line1[0], line2[0]]\n",
    "labels = [line.get_label() for line in lines]\n",
    "plt.legend(lines, labels, loc='center left', frameon=True)\n",
    "# 6) save the line chart\n",
    "plt.savefig('line_chart.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d89db-d328-40b5-8a3d-52024398b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data\n",
    "nltk_main_dataset.to_csv('nltk-main-dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
